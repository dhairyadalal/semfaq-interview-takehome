{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install annoy > null\n",
    "!pip install rank-bm25 > null\n",
    "!pip install -U sentence-transformers > null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "For this take home exercise, we hope provide you with a sense of the challenges this role will be tackling. Posh provides coversational AI solutions for credit unions and banks. Our chatbots and IVR agents often are required to support FAQs. One the underlying systems that the NLP team manages is the SemFAQ service which creates a semantic index over FAQs. When users ask question, we use SemFAQ to match the closest semantically relevant question and return an answer. This take home exercise simulates a simplified version of our production system. It consists of a set of tasks that will have you build querying logic and evalutae the performance of the system which should reflect some of the actually challenge this role will be tackling. The in-person interview will cover your solutions to this take-home exercise and broadly explore your thoughts on the some active problems we're trying to solve in this space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Indices\n",
    "\n",
    "In this section we'll create a semantic and lexical index for our corpus. This corpus consists of FAQ questions scraped from the Consumer Financial Protection Bureau. The goal of this SemFAQ simulation is return the document uuid of the FAQ that most closely matches the user question. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How do I find my state's bank regulator?</td>\n",
       "      <td>Take a look at our list of state banking regul...</td>\n",
       "      <td>hj3Rfuw4Ma6B9MN5xKJY8J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Can I be personally responsible for paying my ...</td>\n",
       "      <td>In most cases you will not be responsible to p...</td>\n",
       "      <td>KitTQDCXSTZNxUhhMwPHpM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What can I do if I can’t repay my payday loan?</td>\n",
       "      <td>If you’re having trouble repaying your payday ...</td>\n",
       "      <td>gBGm4SsW94nsUbEw2UG5GT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>If someone dies owing a debt, does the debt go...</td>\n",
       "      <td>No, when someone dies owing a debt, the debt d...</td>\n",
       "      <td>gn6kqZNaUGfDnVBf7Yt9C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Can the dealer increase the interest rate afte...</td>\n",
       "      <td>Some dealers will allow the customer to take p...</td>\n",
       "      <td>7T2JvSnbvWNNecQrvZmKs8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0           How do I find my state's bank regulator?   \n",
       "1           1  Can I be personally responsible for paying my ...   \n",
       "2           2     What can I do if I can’t repay my payday loan?   \n",
       "3           3  If someone dies owing a debt, does the debt go...   \n",
       "4           4  Can the dealer increase the interest rate afte...   \n",
       "\n",
       "                                                text                    uuid  \n",
       "0  Take a look at our list of state banking regul...  hj3Rfuw4Ma6B9MN5xKJY8J  \n",
       "1  In most cases you will not be responsible to p...  KitTQDCXSTZNxUhhMwPHpM  \n",
       "2  If you’re having trouble repaying your payday ...  gBGm4SsW94nsUbEw2UG5GT  \n",
       "3  No, when someone dies owing a debt, the debt d...  gn6kqZNaUGfDnVBf7Yt9C4  \n",
       "4  Some dealers will allow the customer to take p...  7T2JvSnbvWNNecQrvZmKs8  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "\n",
    "# Load corpus for our indices\n",
    "docs = pd.read_csv(\"data/index_docs.csv\")\n",
    "\n",
    "# Preview of the corpus\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Text for BM25 Index\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"ner\"])\n",
    "def clean_lemmatize(text):\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    toks = [tok.lemma_ for tok in nlp(clean_text) if tok.text.strip() != \"\"]\n",
    "    return toks\n",
    "\n",
    "docs[\"toks\"] = docs[\"title\"].apply(lambda x: clean_lemmatize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and cache Lexical Index using BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import pickle \n",
    "\n",
    "bm25_idx = BM25Okapi(docs[\"toks\"].tolist())\n",
    "\n",
    "pickle.dump(bm25_idx, open(\"bm25_idx.pkl\", \"wb\"))\n",
    "print(\"Finished caching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and cache semantic index using Annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Generate embeddigns using SentenceTransformers \n",
    "doc_embeddings = model.encode(docs[\"title\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building index\n",
      "Finished building and caching semantic index\n"
     ]
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "# Build simple vector index\n",
    "dim = 768\n",
    "idx = AnnoyIndex(dim, \"angular\")\n",
    "\n",
    "for i,e in enumerate(doc_embeddings):\n",
    "    idx.add_item(i, e)\n",
    "    \n",
    "print(\"building index\")    \n",
    "idx.build(1000)\n",
    "\n",
    "idx.save(\"semantic_idx.ann\")\n",
    "print(\"Finished building and caching semantic index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Code\n",
    "\n",
    "The code below creates classes for the semantic and lexical index and provides supporting query methods. Note documents are indexed in they appear in teh `docs` dataframe. Both index classes will return a numerical index value to the docs dataframe. The relevant document uuid can be found by referencing the docs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "from annoy import AnnoyIndex\n",
    "import pickle \n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from typing import Tuple, List \n",
    "\n",
    "class BM25Index():\n",
    "    def __init__(self, \n",
    "                 idx_loc: str=\"bm25_idx.pkl\", \n",
    "                 idx_type: str = \"bm250kpi\"):\n",
    "        self.idx = pickle.load(open(idx_loc, \"rb\"))\n",
    "        self.idx_type = idx_type\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"ner\"])\n",
    "           \n",
    "    def query(self, text: str, num_results: int=5) -> List[Tuple[int, float]]:\n",
    "        \"\"\" Method queries cached bm25 index and return top N results. Returns a\n",
    "            a list of tuples, where first element is document numerical id and \n",
    "            second element is the raw bm25 score.\"\"\"\n",
    "        query_toks = self.preprocess_query(text)\n",
    "        scores = self.idx.get_scores(query_toks)\n",
    "        sorted_doc_ids = np.argsort(scores)[::-1][:num_results]\n",
    "        sorted_scores = [scores[idx] for idx in sorted_doc_ids]\n",
    "        return list(zip(sorted_doc_ids.tolist(), sorted_scores))  \n",
    "\n",
    "    def preprocess_query(self, text: str) -> List[str]:\n",
    "        \"\"\" Prepare text for querying BM25 index. Text is cleaned, lemmatized and tokenized.\n",
    "            Method returns a list of tokens. \"\"\"\n",
    "        clean_text = re.sub(r'[^\\w\\s]', '', text.lower())        \n",
    "        toks = []\n",
    "        for tok in self.nlp(clean_text):\n",
    "            if tok.text not in STOP_WORDS and tok.text.strip() != \"\":\n",
    "                toks.append(tok.lemma_)\n",
    "        return toks\n",
    "\n",
    "class SemanticIndex():\n",
    "    def __init__(self, \n",
    "                 semantic_weights = \"all-mpnet-base-v2\",\n",
    "                 idx_dim=768,\n",
    "                 cache_loc=\"semantic_idx.ann\"):\n",
    "        self.model = SentenceTransformer(semantic_weights)\n",
    "\n",
    "        self.idx = AnnoyIndex(idx_dim, \"angular\")\n",
    "        self.idx.load(cache_loc, True)\n",
    "    \n",
    "    def cosine_similarity_transform(self, angular_distance: float) -> float:\n",
    "        \"\"\" Convert angular distance into cosine similairty score \"\"\"\n",
    "        return (2-(angular_distance**2)) / 2\n",
    "    \n",
    "    def query(self, text: str, num_results: int=5) -> List[Tuple[int, float]]:\n",
    "        \"\"\" Method queries semantic index and return top N results. Returns a\n",
    "            a list of tuples, where first element is document numerical id and \n",
    "            second element is the cosine similarity score. \n",
    "        \"\"\"\n",
    "        encoded_query = self.model.encode(text)\n",
    "        doc_idxs, distances = self.idx.get_nns_by_vector(encoded_query, num_results, search_k=-1, include_distances=True)\n",
    "        scores = [self.cosine_similarity_transform(dist) for dist in distances]\n",
    "        return list(zip(doc_idxs, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Take Home Exercises\n",
    "### A.) Task: Implement a naive voting scheme to rank results from both indices\n",
    "\n",
    "For this exercise we'll walk through creating a Query class. This class will contain the logic and query calls to query the lexical and semantic indices. The goal is create a simple class that provided a user query will return the closest documents based on lexical and semantic similarity. \n",
    "\n",
    "The `SemanticIndex` and `BM25Index` classes both contain query methods that will query the respectives indices and return a set of relevant document id and scores. Your task is to define a logic that selects the best result provided results from the semantic and lexical index. To help familiarize you with the code, we'll walk through implement a simple voting based logc for returning a query. The next exercise will ask you to improve the query logic and you will free to use choose whatever methodology and logic you care to.\n",
    "\n",
    "The code below describes how to query the indices and return relevant documents uuids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result idx 34 | Result score 0.8249342939786217\n",
      "Document title: If I can’t make my auto loan payments, will my vehicle be repossessed? | Document uuid: 4bMJCVYav2Ux8BqZFWXT4j\n",
      "------------\n",
      "Result idx 188 | Result score 0.6808710552168815\n",
      "Document title: What should I do if I have problems making my auto loan payments? | Document uuid: cUQV8w9vCk3vWXiVzLDkQc\n",
      "------------\n",
      "Result idx 104 | Result score 0.6788633475174617\n",
      "Document title: What happens if I don’t make the payments on my auto lease? | Document uuid: Q5oynF83ykEDD3yyYdg3wk\n",
      "------------\n",
      "Result idx 191 | Result score 0.6668141843904039\n",
      "Document title: What happens to my credit report if I am late making payments on my auto loan or my car is repossessed? | Document uuid: BLgTGfBWEBQzck3cFU7DpQ\n",
      "------------\n",
      "Result idx 195 | Result score 0.6559985774376127\n",
      "Document title: My car has been repossessed, and I was told it will be sold. What can I do? | Document uuid: ktq5ZmiKPwjfjqe2pkfHTW\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prefault is set to true, but MAP_POPULATE is not defined on this platform"
     ]
    }
   ],
   "source": [
    "# Example of querying semantic index\n",
    "# create a semantic index object\n",
    "sem_idx = SemanticIndex()\n",
    "\n",
    "# Query index. Index will return a list of tuples. First element contains document index and second contains the score. \n",
    "results = sem_idx.query(\"Will my car be taken if I fail to pay my auto loan?\")\n",
    "\n",
    "# We resolve the document ids into uuids and raw titles by looking them up in the docs dataframe.\n",
    "for result in results:\n",
    "    print(f\"Result idx {result[0]} | Result score {result[1]}\")\n",
    "    print(f\"Document title: {docs.iloc[result[0]].title} | Document uuid: {docs.iloc[result[0]].uuid}\")\n",
    "    print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result idx 191 | Result score 7.892702494670768\n",
      "Document title: What happens to my credit report if I am late making payments on my auto loan or my car is repossessed? | Document uuid: BLgTGfBWEBQzck3cFU7DpQ\n",
      "------------\n",
      "Result idx 193 | Result score 7.723089911354117\n",
      "Document title: What is a “no credit check\" or “buy here, pay here” auto loan? | Document uuid: h6RhihYnKDVCMnWc2TbAKS\n",
      "------------\n",
      "Result idx 169 | Result score 6.637430659552135\n",
      "Document title: I bought a used car and financed it at the dealership. They told me that the car was in good shape, but it turned out to have serious mechanical problems. The dealer says the warranty doesn't cover any of the problems. I can't afford to pay my loan payment and get the car fixed. What can I do? | Document uuid: 5oxJppq39oC9UeBqvAwmwe\n",
      "------------\n",
      "Result idx 208 | Result score 5.46317950375905\n",
      "Document title: Should I have car insurance lined up before I purchase a vehicle? | Document uuid: CFkfkm2fpDNFV7gZLxJPxE\n",
      "------------\n",
      "Result idx 365 | Result score 5.376722442674351\n",
      "Document title: What is an assignee of an auto loan? | Document uuid: n7KLRXN9jT6wHPz74EFue3\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# The logic for querying the lexical index is similar\n",
    "bm25_idx = BM25Index()\n",
    "\n",
    "# Query index. Index will return a list of tuples. First element contains document index and second contains the score.\n",
    "results = bm25_idx.query(\"Will my car be taken if I fail to pay my auto loan?\")\n",
    "\n",
    "# We resolve the document ids into uuids and raw titles by looking them up in the docs dataframe.\n",
    "for result in results:\n",
    "    print(f\"Result idx {result[0]} | Result score {result[1]}\")\n",
    "    print(f\"Document title: {docs.iloc[result[0]].title} | Document uuid: {docs.iloc[result[0]].uuid}\")\n",
    "    print(\"------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the example code above, fill out the logic in the `rank_results` class below. The naive voting logic should do the following provided a list tuples which consist of the document id and score:\n",
    "1. group the ids and sum all the scores\n",
    "2. rerank the documents in descending order based on the summed scores\n",
    "3. return depluciated list of documents and the summed scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prefault is set to true, but MAP_POPULATE is not defined on this platform"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4bMJCVYav2Ux8BqZFWXT4j'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Query():   \n",
    "    def __init__(self) -> None:\n",
    "        self.semantic_idx = SemanticIndex()\n",
    "        self.lexical_idx = BM25Index()\n",
    "        self.document_df = pd.read_csv(\"data/index_docs.csv\")\n",
    "               \n",
    "    def query(self, text: str) -> str:\n",
    "        \"\"\" Method takes in query and return the uuid of the best document that\n",
    "            matches the query text.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Query indices\n",
    "        sem_results = self.semantic_idx.query(text)\n",
    "        lexical_results = self.lexical_idx.query(text)\n",
    "        \n",
    "        # 2. Combine the results into a single list \n",
    "        sem_results.extend(lexical_results)\n",
    "        \n",
    "        # 3. Dedup and rank the results\n",
    "        ranked_results = self.rank_results(sem_results)\n",
    "        \n",
    "        # 4. Return top result uuid\n",
    "        top_result = ranked_results[0][0]\n",
    "        return self.document_df.iloc[top_result].uuid \n",
    "            \n",
    "    def rank_results(self, results: List[Tuple[int, float]]) -> List[Tuple[int, float]]:\n",
    "        # Implement your voting logic here.  \n",
    "        return results\n",
    "\n",
    "query_obj = Query()\n",
    "query_obj.query(\"What happens to my car if I can't pay my loan?\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.) Evaluate performance on sample queries\n",
    "\n",
    "In this section we'll evaluate the performance of the `Query` class on a set of generated queries. Run the code below to run the queries and get the predicted document uuids. You'll notice that there is a type column which classifies the query as either paraphrase or keyword. This category designates whether the simulated query was generated using a paraphrasing technique (on the header) or a keyword extraction technique. For our product we often see users ask well formed questions or provide short keyword style inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>type</th>\n",
       "      <th>gold_uid</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>information debt collector debt</td>\n",
       "      <td>keyword</td>\n",
       "      <td>RYaR2WYJssw5xcPvPXCJgp</td>\n",
       "      <td>RYaR2WYJssw5xcPvPXCJgp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit union share draft account</td>\n",
       "      <td>keyword</td>\n",
       "      <td>7z2jYhbY4ZiG8DKHh2mSn3</td>\n",
       "      <td>7z2jYhbY4ZiG8DKHh2mSn3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can i apply for a credit card with one set of ...</td>\n",
       "      <td>paraphrase</td>\n",
       "      <td>GgS3M8h8998z6nc5mPR5vA</td>\n",
       "      <td>GgS3M8h8998z6nc5mPR5vA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if my credit card doesn't work what can i do?</td>\n",
       "      <td>paraphrase</td>\n",
       "      <td>CVcjcDMjxsqCizWrsT3R5u</td>\n",
       "      <td>CVcjcDMjxsqCizWrsT3R5u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>request credit report child</td>\n",
       "      <td>keyword</td>\n",
       "      <td>CE3RKEmS4ujtA2TfE3v2KP</td>\n",
       "      <td>CE3RKEmS4ujtA2TfE3v2KP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query        type  \\\n",
       "0                    information debt collector debt     keyword   \n",
       "1                   credit union share draft account     keyword   \n",
       "2  can i apply for a credit card with one set of ...  paraphrase   \n",
       "3      if my credit card doesn't work what can i do?  paraphrase   \n",
       "4                        request credit report child     keyword   \n",
       "\n",
       "                 gold_uid               predicted  \n",
       "0  RYaR2WYJssw5xcPvPXCJgp  RYaR2WYJssw5xcPvPXCJgp  \n",
       "1  7z2jYhbY4ZiG8DKHh2mSn3  7z2jYhbY4ZiG8DKHh2mSn3  \n",
       "2  GgS3M8h8998z6nc5mPR5vA  GgS3M8h8998z6nc5mPR5vA  \n",
       "3  CVcjcDMjxsqCizWrsT3R5u  CVcjcDMjxsqCizWrsT3R5u  \n",
       "4  CE3RKEmS4ujtA2TfE3v2KP  CE3RKEmS4ujtA2TfE3v2KP  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pd.read_csv(\"data/query_sample.csv\")[:10]\n",
    "\n",
    "queries[\"predicted\"] = queries[\"query\"].apply(lambda x: query_obj.query(x))\n",
    "\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Analyze results\n",
    "Analyze the performance predictions above. What metrics do you think would be helpful in evaluating the accuracy and relevancy of the results being results? At mininum implement two metrics in code below and describe how we should interpret those results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* your analysis here *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Task: Improvement ranking logic. \n",
    "\n",
    "In this section you will have the opportunity to improve the system above. You're welcome to change any of the logic and infrastructure (eg changing embeddings, distance metrics etc) above. Develop your POC below and provide an updated evaluation on the sample queries. For the in person interview, we'll walk through your thoughts. If you have ideas that are more complex, it's ok if you are unable to implement them. We can talk through those in the interview as well.\n",
    "\n",
    "At minimum we'd like to see some basic improvements to the ranking logic implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "365b6971d126e4e0b148ffa3b4c04bdc50defffe2b5d99761d5bec5365a62ac6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('nlp-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
